# Multi-Label-Text-Classification-Using-LSTM

Long Short Term Memory Network is an advanced RNN, a sequential network, that allows information to persist. It is capable of handling the vanishing gradient problem faced by RNN. A recurrent neural network is also known as RNN is used for persistent memory.
Letâ€™s say while watching a video you remember the previous scene or while reading a book you know what happened in the earlier chapter. Similarly RNNs work, they remember the previous information and use it for processing the current input. The shortcoming of RNN is, they can not remember Long term dependencies due to vanishing gradient. LSTMs are explicitly designed to avoid long-term dependency problems.
Note: If you are more interested in learning concepts in an Audio-Visual format, We have this entire article explained in the video below. If not, you may continue reading.
![1_UiZX9ZKImH9B3gCp9VVRmw](https://user-images.githubusercontent.com/79834087/172399341-c5e6ce29-7e2e-43e1-a070-2f431e0cfc82.png)
